{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Map 补全任务 - 基于RME-GAN的实现\n",
    "\n",
    "## 任务说明\n",
    "- 输入：带有20%像素缺失的Radio Map（256×256灰度图）\n",
    "- 输出：完整的Radio Map预测\n",
    "- 评估指标：NMSE (Normalized Mean Square Error)\n",
    "- 框架：PyTorch\n",
    "- 方法：基于RME-GAN（条件生成对抗网络）的改进版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置和导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础库\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch相关\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "# 设置随机种子\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 检查GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据路径配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径\n",
    "BASE_PATH = r'E:\\Ungraduate_Studies_UJS\\Year2_I\\智能通信技术基础\\homeworks\\03_Final_RadioMap_Completion'\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, 'Data', 'train')\n",
    "TEST_PATH = os.path.join(BASE_PATH, 'Data', 'test(student)')\n",
    "MASK_PATH = os.path.join(TEST_PATH, 'mask.csv')\n",
    "\n",
    "# 输出路径\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, 'output')\n",
    "MODEL_PATH = os.path.join(BASE_PATH, 'models')\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"训练数据路径: {TRAIN_PATH}\")\n",
    "print(f\"测试数据路径: {TEST_PATH}\")\n",
    "print(f\"遮罩文件路径: {MASK_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取mask信息\n",
    "def load_masks(mask_path):\n",
    "    \"\"\"加载遮罩位置信息\"\"\"\n",
    "    masks = []\n",
    "    with open(mask_path, 'r') as f:\n",
    "        for line in f:\n",
    "            coords = line.strip().split(',')\n",
    "            if len(coords) == 4:\n",
    "                masks.append([int(x) for x in coords])\n",
    "    return masks\n",
    "\n",
    "# 应用遮罩到图像\n",
    "def apply_masks_to_image(img, masks, fill_value=1.0):\n",
    "    \"\"\"将遮罩应用到图像上\"\"\"\n",
    "    img_masked = img.copy()\n",
    "    mask_binary = np.ones_like(img)\n",
    "    \n",
    "    for mask in masks:\n",
    "        x1, y1, x2, y2 = mask\n",
    "        # 注意坐标转换，图像坐标系和数组坐标系不同\n",
    "        img_masked[y1:y2, x1:x2] = fill_value\n",
    "        mask_binary[y1:y2, x1:x2] = 0\n",
    "    \n",
    "    return img_masked, mask_binary\n",
    "\n",
    "# 自定义数据集\n",
    "class RadioMapDataset(Dataset):\n",
    "    def __init__(self, data_path, masks=None, mode='train', transform=None):\n",
    "        \"\"\"\n",
    "        mode: 'train', 'val', or 'test'\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.masks = masks\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 获取所有图像文件\n",
    "        self.image_files = sorted([f for f in os.listdir(data_path) if f.endswith('.png')])\n",
    "        \n",
    "        if mode == 'train':\n",
    "            # 训练集划分：90%训练，10%验证\n",
    "            n_train = int(len(self.image_files) * 0.9)\n",
    "            self.image_files = self.image_files[:n_train]\n",
    "        elif mode == 'val':\n",
    "            n_train = int(len(self.image_files) * 0.9)\n",
    "            self.image_files = self.image_files[n_train:]\n",
    "            \n",
    "        print(f\"{mode} dataset size: {len(self.image_files)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 读取图像\n",
    "        img_path = os.path.join(self.data_path, self.image_files[idx])\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img = np.array(img, dtype=np.float32) / 255.0  # 归一化到[0,1]\n",
    "        \n",
    "        if self.mode in ['train', 'val']:\n",
    "            # 训练/验证模式：随机添加遮罩\n",
    "            if self.masks:\n",
    "                # 随机选择一些遮罩\n",
    "                n_masks = random.randint(5, min(20, len(self.masks)))\n",
    "                selected_masks = random.sample(self.masks, n_masks)\n",
    "                img_masked, mask_binary = apply_masks_to_image(img, selected_masks)\n",
    "            else:\n",
    "                # 如果没有提供遮罩，随机生成\n",
    "                img_masked, mask_binary = self.generate_random_masks(img)\n",
    "            \n",
    "            # 转换为张量\n",
    "            img_tensor = torch.from_numpy(img).unsqueeze(0)  # [1, H, W]\n",
    "            img_masked_tensor = torch.from_numpy(img_masked).unsqueeze(0)\n",
    "            mask_tensor = torch.from_numpy(mask_binary).unsqueeze(0)\n",
    "            \n",
    "            return {\n",
    "                'input': img_masked_tensor,\n",
    "                'target': img_tensor,\n",
    "                'mask': mask_tensor,\n",
    "                'filename': self.image_files[idx]\n",
    "            }\n",
    "        else:\n",
    "            # 测试模式\n",
    "            if self.masks:\n",
    "                img_masked, mask_binary = apply_masks_to_image(img, self.masks)\n",
    "            else:\n",
    "                img_masked = img\n",
    "                mask_binary = np.ones_like(img)\n",
    "            \n",
    "            img_masked_tensor = torch.from_numpy(img_masked).unsqueeze(0)\n",
    "            mask_tensor = torch.from_numpy(mask_binary).unsqueeze(0)\n",
    "            \n",
    "            return {\n",
    "                'input': img_masked_tensor,\n",
    "                'mask': mask_tensor,\n",
    "                'filename': self.image_files[idx]\n",
    "            }\n",
    "    \n",
    "    def generate_random_masks(self, img):\n",
    "        \"\"\"生成随机遮罩\"\"\"\n",
    "        h, w = img.shape\n",
    "        img_masked = img.copy()\n",
    "        mask_binary = np.ones_like(img)\n",
    "        \n",
    "        # 生成10-20个随机矩形遮罩\n",
    "        n_masks = random.randint(10, 20)\n",
    "        for _ in range(n_masks):\n",
    "            # 随机大小和位置\n",
    "            mask_h = random.randint(5, 15)\n",
    "            mask_w = random.randint(5, 15)\n",
    "            x = random.randint(0, w - mask_w)\n",
    "            y = random.randint(0, h - mask_h)\n",
    "            \n",
    "            img_masked[y:y+mask_h, x:x+mask_w] = 1.0\n",
    "            mask_binary[y:y+mask_h, x:x+mask_w] = 0\n",
    "        \n",
    "        return img_masked, mask_binary\n",
    "\n",
    "# 加载遮罩信息\n",
    "masks = load_masks(MASK_PATH)\n",
    "print(f\"加载了 {len(masks)} 个遮罩\")\n",
    "print(f\"示例遮罩: {masks[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型架构定义 - ResNet生成器（来自RME-GAN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet块定义\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"ResNet残差块\"\"\"\n",
    "    def __init__(self, dim, padding_type='reflect', norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        \n",
    "        # 第一个卷积层\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError(f'padding {padding_type} is not implemented')\n",
    "\n",
    "        conv_block += [\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "            norm_layer(dim),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "        \n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        # 第二个卷积层\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "            \n",
    "        conv_block += [\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "            norm_layer(dim)\n",
    "        ]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)  # 残差连接\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet生成器\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"基于ResNet的生成器网络\"\"\"\n",
    "    def __init__(self, input_nc=2, output_nc=1, ngf=64, norm_layer=nn.BatchNorm2d, \n",
    "                 use_dropout=False, n_blocks=4, padding_type='reflect'):\n",
    "        \"\"\"\n",
    "        input_nc: 输入通道数（带遮罩图像 + 遮罩二值图）\n",
    "        output_nc: 输出通道数\n",
    "        ngf: 生成器基础特征数\n",
    "        n_blocks: ResNet块数量\n",
    "        \"\"\"\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        \n",
    "        # 初始卷积块\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "            norm_layer(ngf),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "        \n",
    "        # 下采样\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** i\n",
    "            model += [\n",
    "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                norm_layer(ngf * mult * 2),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "        \n",
    "        # ResNet块\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, \n",
    "                                use_dropout=use_dropout, use_bias=use_bias)]\n",
    "        \n",
    "        # 上采样\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), \n",
    "                                   kernel_size=3, stride=2, padding=1, output_padding=1, bias=use_bias),\n",
    "                norm_layer(int(ngf * mult / 2)),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "        \n",
    "        # 输出层\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n",
    "            nn.Sigmoid()  # 输出范围[0,1]\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# 简化版U-Net（备选方案）\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"简化的U-Net架构，作为备选方案\"\"\"\n",
    "    def __init__(self, in_channels=2, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        for feature in features:\n",
    "            self.encoder.append(self._block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._block(features[-1], features[-1]*2)\n",
    "        \n",
    "        # Decoder\n",
    "        for feature in reversed(features):\n",
    "            self.decoder.append(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.decoder.append(self._block(feature*2, feature))\n",
    "        \n",
    "        # Final conv\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Encoder\n",
    "        for down in self.encoder:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        # Decoder\n",
    "        for idx in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            x = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.decoder[idx+1](x)\n",
    "        \n",
    "        return self.sigmoid(self.final_conv(x))\n",
    "\n",
    "\n",
    "# 测试模型结构\n",
    "def test_model():\n",
    "    # 创建模型\n",
    "    model = ResnetGenerator(input_nc=2, output_nc=1, ngf=64, n_blocks=4)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 测试输入\n",
    "    test_input = torch.randn(2, 2, 256, 256).to(device)\n",
    "    \n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        output = model(test_input)\n",
    "    \n",
    "    print(f\"输入尺寸: {test_input.shape}\")\n",
    "    print(f\"输出尺寸: {output.shape}\")\n",
    "    \n",
    "    # 计算参数量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"总参数量: {total_params:,}\")\n",
    "    print(f\"可训练参数量: {trainable_params:,}\")\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 损失函数定义（RME-GAN的多重损失）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TV损失（Total Variation Loss）\n",
    "class TVLoss(nn.Module):\n",
    "    \"\"\"总变分损失，用于保证图像平滑性\"\"\"\n",
    "    def __init__(self, weight=1e-6):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self._tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self._tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x-1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x-1]), 2).sum()\n",
    "        return self.weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "    \n",
    "    def _tensor_size(self, t):\n",
    "        return t.size(1) * t.size(2) * t.size(3)\n",
    "\n",
    "\n",
    "# 梯度损失\n",
    "class GradientLoss(nn.Module):\n",
    "    \"\"\"梯度损失，用于保持边缘信息\"\"\"\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(GradientLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "        # Sobel算子\n",
    "        self.sobel_x = nn.Conv2d(1, 1, 3, 1, 1, bias=False)\n",
    "        self.sobel_y = nn.Conv2d(1, 1, 3, 1, 1, bias=False)\n",
    "        \n",
    "        sobel_x_kernel = torch.tensor([[[[-1, 0, 1],\n",
    "                                         [-2, 0, 2],\n",
    "                                         [-1, 0, 1]]]], dtype=torch.float32)\n",
    "        sobel_y_kernel = torch.tensor([[[[-1, -2, -1],\n",
    "                                         [0, 0, 0],\n",
    "                                         [1, 2, 1]]]], dtype=torch.float32)\n",
    "        \n",
    "        self.sobel_x.weight = nn.Parameter(sobel_x_kernel, requires_grad=False)\n",
    "        self.sobel_y.weight = nn.Parameter(sobel_y_kernel, requires_grad=False)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # 计算梯度\n",
    "        pred_grad_x = self.sobel_x(pred)\n",
    "        pred_grad_y = self.sobel_y(pred)\n",
    "        target_grad_x = self.sobel_x(target)\n",
    "        target_grad_y = self.sobel_y(target)\n",
    "        \n",
    "        # 计算梯度差异\n",
    "        loss_x = F.l1_loss(pred_grad_x, target_grad_x)\n",
    "        loss_y = F.l1_loss(pred_grad_y, target_grad_y)\n",
    "        \n",
    "        return self.weight * (loss_x + loss_y)\n",
    "\n",
    "\n",
    "# 组合损失\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"组合多个损失函数\"\"\"\n",
    "    def __init__(self, mse_weight=1.0, tv_weight=1e-6, grad_weight=0.1):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss(weight=tv_weight)\n",
    "        self.grad_loss = GradientLoss(weight=grad_weight)\n",
    "        \n",
    "        self.mse_weight = mse_weight\n",
    "        self.losses = {}\n",
    "    \n",
    "    def forward(self, pred, target, mask=None):\n",
    "        # MSE损失（主要损失）\n",
    "        if mask is not None:\n",
    "            # 只在缺失区域计算损失\n",
    "            mse = self.mse_loss(pred * (1 - mask), target * (1 - mask))\n",
    "        else:\n",
    "            mse = self.mse_loss(pred, target)\n",
    "        \n",
    "        # TV损失\n",
    "        tv = self.tv_loss(pred)\n",
    "        \n",
    "        # 梯度损失\n",
    "        grad = self.grad_loss(pred, target)\n",
    "        \n",
    "        # 记录各项损失\n",
    "        self.losses = {\n",
    "            'mse': mse.item(),\n",
    "            'tv': tv.item(),\n",
    "            'grad': grad.item()\n",
    "        }\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = self.mse_weight * mse + tv + grad\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "# NMSE计算（用于评估）\n",
    "def calculate_nmse(pred, target, mask=None):\n",
    "    \"\"\"计算NMSE（归一化均方误差）\"\"\"\n",
    "    if mask is not None:\n",
    "        # 只在缺失区域计算\n",
    "        diff = (pred - target) * (1 - mask)\n",
    "        mse = torch.mean(diff ** 2)\n",
    "    else:\n",
    "        mse = torch.mean((pred - target) ** 2)\n",
    "    \n",
    "    return mse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "class Config:\n",
    "    # 数据相关\n",
    "    batch_size = 8\n",
    "    num_workers = 2\n",
    "    \n",
    "    # 模型相关\n",
    "    model_type = 'resnet'  # 'resnet' or 'unet'\n",
    "    ngf = 64  # 生成器特征数\n",
    "    n_blocks = 4  # ResNet块数量\n",
    "    use_dropout = False\n",
    "    \n",
    "    # 训练相关\n",
    "    epochs = 100\n",
    "    learning_rate = 0.0002\n",
    "    beta1 = 0.5  # Adam优化器参数\n",
    "    beta2 = 0.999\n",
    "    \n",
    "    # 损失函数权重\n",
    "    mse_weight = 1.0\n",
    "    tv_weight = 1e-6\n",
    "    grad_weight = 0.1\n",
    "    \n",
    "    # 其他\n",
    "    save_interval = 10  # 每N个epoch保存一次模型\n",
    "    log_interval = 100  # 每N个batch打印一次日志\n",
    "    val_interval = 5  # 每N个epoch验证一次\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = RadioMapDataset(TRAIN_PATH, masks=masks, mode='train')\n",
    "val_dataset = RadioMapDataset(TRAIN_PATH, masks=masks, mode='val')\n",
    "test_dataset = RadioMapDataset(TEST_PATH, masks=masks, mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, \n",
    "                         shuffle=True, num_workers=config.num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, \n",
    "                       shuffle=False, num_workers=config.num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, \n",
    "                        shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "print(f\"训练批次数: {len(train_loader)}\")\n",
    "print(f\"验证批次数: {len(val_loader)}\")\n",
    "print(f\"测试批次数: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 训练和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch, config):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_nmse = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch}/{config.epochs}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # 准备数据\n",
    "        input_img = batch['input'].to(device)\n",
    "        target_img = batch['target'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        \n",
    "        # 拼接输入（遮罩图像 + 遮罩二值图）\n",
    "        model_input = torch.cat([input_img, mask], dim=1)\n",
    "        \n",
    "        # 前向传播\n",
    "        optimizer.zero_grad()\n",
    "        output = model(model_input)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(output, target_img, mask)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计\n",
    "        running_loss += loss.item()\n",
    "        nmse = calculate_nmse(output, target_img, mask)\n",
    "        running_nmse += nmse\n",
    "        \n",
    "        # 更新进度条\n",
    "        if batch_idx % 10 == 0:\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'NMSE': f'{nmse:.4f}',\n",
    "                'MSE': f'{criterion.losses.get(\"mse\", 0):.4f}',\n",
    "                'TV': f'{criterion.losses.get(\"tv\", 0):.6f}',\n",
    "                'Grad': f'{criterion.losses.get(\"grad\", 0):.4f}'\n",
    "            })\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_nmse = running_nmse / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_nmse\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"验证模型\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_nmse = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Validation'):\n",
    "            # 准备数据\n",
    "            input_img = batch['input'].to(device)\n",
    "            target_img = batch['target'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            \n",
    "            # 拼接输入\n",
    "            model_input = torch.cat([input_img, mask], dim=1)\n",
    "            \n",
    "            # 前向传播\n",
    "            output = model(model_input)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(output, target_img, mask)\n",
    "            nmse = calculate_nmse(output, target_img, mask)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_nmse += nmse\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_nmse = running_nmse / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_nmse\n",
    "\n",
    "\n",
    "def visualize_results(model, dataloader, device, num_samples=4):\n",
    "    \"\"\"可视化预测结果\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(12, 3*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            # 准备数据\n",
    "            input_img = batch['input'].to(device)\n",
    "            target_img = batch['target'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            \n",
    "            # 拼接输入\n",
    "            model_input = torch.cat([input_img, mask], dim=1)\n",
    "            \n",
    "            # 前向传播\n",
    "            output = model(model_input)\n",
    "            \n",
    "            # 转换为numpy\n",
    "            input_np = input_img[0, 0].cpu().numpy()\n",
    "            target_np = target_img[0, 0].cpu().numpy()\n",
    "            output_np = output[0, 0].cpu().numpy()\n",
    "            mask_np = mask[0, 0].cpu().numpy()\n",
    "            \n",
    "            # 显示图像\n",
    "            axes[i, 0].imshow(input_np, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 0].set_title('Input (with mask)')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(target_np, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 1].set_title('Target')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(output_np, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 2].set_title('Prediction')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # 差异图\n",
    "            diff = np.abs(target_np - output_np)\n",
    "            axes[i, 3].imshow(diff, cmap='hot', vmin=0, vmax=0.5)\n",
    "            axes[i, 3].set_title(f'Difference (NMSE: {calculate_nmse(output, target_img, mask):.4f})')\n",
    "            axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 训练主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "if config.model_type == 'resnet':\n",
    "    model = ResnetGenerator(\n",
    "        input_nc=2,  # 输入: 遮罩图像 + 遮罩\n",
    "        output_nc=1,\n",
    "        ngf=config.ngf,\n",
    "        n_blocks=config.n_blocks,\n",
    "        use_dropout=config.use_dropout\n",
    "    )\n",
    "else:\n",
    "    model = SimpleUNet(in_channels=2, out_channels=1)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 损失函数\n",
    "criterion = CombinedLoss(\n",
    "    mse_weight=config.mse_weight,\n",
    "    tv_weight=config.tv_weight,\n",
    "    grad_weight=config.grad_weight\n",
    ")\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    betas=(config.beta1, config.beta2)\n",
    ")\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "\n",
    "# 训练历史\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_nmse': [],\n",
    "    'val_loss': [],\n",
    "    'val_nmse': []\n",
    "}\n",
    "\n",
    "best_val_nmse = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "# 训练循环\n",
    "print(\"开始训练...\")\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    # 训练\n",
    "    train_loss, train_nmse = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch, config\n",
    "    )\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_nmse'].append(train_nmse)\n",
    "    \n",
    "    # 验证\n",
    "    if epoch % config.val_interval == 0:\n",
    "        val_loss, val_nmse = validate(model, val_loader, criterion, device)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_nmse'].append(val_nmse)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}: Train Loss: {train_loss:.4f}, Train NMSE: {train_nmse:.4f}\")\n",
    "        print(f\"         Val Loss: {val_loss:.4f}, Val NMSE: {val_nmse:.4f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_nmse < best_val_nmse:\n",
    "            best_val_nmse = val_nmse\n",
    "            best_epoch = epoch\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_nmse': val_nmse,\n",
    "            }, os.path.join(MODEL_PATH, 'best_model.pth'))\n",
    "            print(f\"保存最佳模型 (NMSE: {val_nmse:.4f})\")\n",
    "        \n",
    "        # 可视化结果\n",
    "        if epoch % 20 == 0:\n",
    "            visualize_results(model, val_loader, device, num_samples=3)\n",
    "    \n",
    "    # 调整学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 定期保存模型\n",
    "    if epoch % config.save_interval == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'history': history,\n",
    "        }, os.path.join(MODEL_PATH, f'checkpoint_epoch_{epoch}.pth'))\n",
    "\n",
    "print(f\"\\n训练完成! 最佳模型: Epoch {best_epoch}, NMSE: {best_val_nmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 绘制训练曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练历史\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 损失曲线\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "if history['val_loss']:\n",
    "    ax1.plot(np.arange(config.val_interval-1, len(history['train_loss']), config.val_interval), \n",
    "             history['val_loss'], label='Val Loss', marker='o')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# NMSE曲线\n",
    "ax2.plot(history['train_nmse'], label='Train NMSE')\n",
    "if history['val_nmse']:\n",
    "    ax2.plot(np.arange(config.val_interval-1, len(history['train_nmse']), config.val_interval), \n",
    "             history['val_nmse'], label='Val NMSE', marker='o')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('NMSE')\n",
    "ax2.set_title('Training and Validation NMSE')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, 'training_curves.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 测试集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "checkpoint = torch.load(os.path.join(MODEL_PATH, 'best_model.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"加载最佳模型 (Epoch {checkpoint['epoch']}, Val NMSE: {checkpoint['val_nmse']:.4f})\")\n",
    "\n",
    "# 预测测试集\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        # 准备数据\n",
    "        input_img = batch['input'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        filename = batch['filename'][0]\n",
    "        \n",
    "        # 拼接输入\n",
    "        model_input = torch.cat([input_img, mask], dim=1)\n",
    "        \n",
    "        # 前向传播\n",
    "        output = model(model_input)\n",
    "        \n",
    "        # 保存预测结果\n",
    "        output_np = (output[0, 0].cpu().numpy() * 255).astype(np.uint8)\n",
    "        output_img = Image.fromarray(output_np, mode='L')\n",
    "        \n",
    "        # 保存图像\n",
    "        output_path = os.path.join(OUTPUT_PATH, f'pred_{filename}')\n",
    "        output_img.save(output_path)\n",
    "        \n",
    "        predictions.append({\n",
    "            'filename': filename,\n",
    "            'output_path': output_path\n",
    "        })\n",
    "\n",
    "print(f\"\\n测试完成! 预测结果保存在: {OUTPUT_PATH}\")\n",
    "print(f\"共预测 {len(predictions)} 张图像\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 结果分析和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选择一些测试结果进行可视化\n",
    "def visualize_test_results(test_loader, model, device, num_samples=6):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(10, 3*num_samples))\n",
    "    \n",
    "    # 随机选择样本\n",
    "    indices = np.random.choice(len(test_loader), num_samples, replace=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, i in enumerate(indices):\n",
    "            # 获取特定批次\n",
    "            batch = next(iter(test_loader))\n",
    "            \n",
    "            # 准备数据\n",
    "            input_img = batch['input'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            \n",
    "            # 拼接输入\n",
    "            model_input = torch.cat([input_img, mask], dim=1)\n",
    "            \n",
    "            # 前向传播\n",
    "            output = model(model_input)\n",
    "            \n",
    "            # 转换为numpy\n",
    "            input_np = input_img[0, 0].cpu().numpy()\n",
    "            output_np = output[0, 0].cpu().numpy()\n",
    "            mask_np = mask[0, 0].cpu().numpy()\n",
    "            \n",
    "            # 显示图像\n",
    "            axes[idx, 0].imshow(input_np, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[idx, 0].set_title('Input (with mask)')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            axes[idx, 1].imshow(output_np, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[idx, 1].set_title('Prediction')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            # 遮罩区域\n",
    "            axes[idx, 2].imshow(1-mask_np, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[idx, 2].set_title('Mask Region')\n",
    "            axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle('Test Set Predictions', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'test_predictions.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 执行可视化\n",
    "visualize_test_results(test_loader, model, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 总结和建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Radio Map补全任务 - 训练总结\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n模型架构: {config.model_type.upper()}\")\n",
    "print(f\"总训练轮数: {config.epochs}\")\n",
    "print(f\"最佳验证NMSE: {best_val_nmse:.4f} (Epoch {best_epoch})\")\n",
    "print(f\"\\n模型参数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"训练数据量: {len(train_dataset)} 张图像\")\n",
    "print(f\"验证数据量: {len(val_dataset)} 张图像\")\n",
    "print(f\"测试数据量: {len(test_dataset)} 张图像\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"优化建议：\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. 数据增强:\n",
    "   - 添加旋转、翻转等数据增强\n",
    "   - 增加噪声扰动提高鲁棒性\n",
    "\n",
    "2. 模型改进:\n",
    "   - 尝试增加ResNet块数量（n_blocks）\n",
    "   - 调整特征通道数（ngf）\n",
    "   - 添加注意力机制\n",
    "\n",
    "3. 损失函数优化:\n",
    "   - 调整各损失权重\n",
    "   - 添加感知损失（Perceptual Loss）\n",
    "   - 尝试SSIM损失\n",
    "\n",
    "4. 训练策略:\n",
    "   - 使用更大的batch size（如果GPU允许）\n",
    "   - 尝试不同的学习率调度策略\n",
    "   - 实施早停（Early Stopping）\n",
    "\n",
    "5. 后处理:\n",
    "   - 对预测结果进行平滑处理\n",
    "   - 集成多个模型的预测结果\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}